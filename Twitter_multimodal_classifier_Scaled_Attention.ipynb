{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arnabbiswas66/multimodal-fake-news-classifier/blob/main/Twitter_multimodal_classifier_Scaled_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "AECm9YZxm322"
      },
      "outputs": [],
      "source": [
        "#!pip install -q -U \"tensorflow-text==2.11.*\"\n",
        "!pip install -q tensorflow_text\n",
        "!pip install -q talos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S0_Dwt-ondpi"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.platform.tf_logging import warn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import re\n",
        "from os import listdir\n",
        "import shutil\n",
        "import glob\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import talos as ta\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x20211H_nnLR",
        "outputId": "520cbc04-5a31-47d2-fdf1-07701571d42c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BbHqdujoUn87"
      },
      "outputs": [],
      "source": [
        "BASE_SAVE_LOCATION = \"/content/drive/MyDrive/multimodal-news\"\n",
        "CHECKPOINT_FILEPATH = '/content/drive/MyDrive/multimodal-news/twitter-models/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKusTHhYWBlz"
      },
      "source": [
        "## Load the dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JftdaRkIWAAo",
        "outputId": "c2213cc1-e74c-4ec9-9e67-bdbab49ec26e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14258, 3) (1923, 3)\n"
          ]
        }
      ],
      "source": [
        "#Load training df\n",
        "train_df_model = pd.read_pickle(BASE_SAVE_LOCATION+\"/twitter-train.pickle\")\n",
        "test_df_model = pd.read_pickle(BASE_SAVE_LOCATION+\"/twitter-test.pickle\")\n",
        "print(train_df_model.shape, test_df_model.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "g3iaPhB7gqdq"
      },
      "outputs": [],
      "source": [
        "# This is for Talos as it doesn't take TF DataSet as input\n",
        "X_train = train_df_model.copy()\n",
        "y_train = X_train.pop('label')\n",
        "\n",
        "X_test = test_df_model.copy()\n",
        "y_test = X_test.pop('label')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCuEsRz4CIdR"
      },
      "source": [
        "# Data input pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sjc2FLKhBfbj"
      },
      "outputs": [],
      "source": [
        "# Define TF Hub paths to the BERT encoder and its preprocessor\n",
        "bert_model_path = (\n",
        "    \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1\"\n",
        ")\n",
        "bert_preprocess_path = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uZzOdgKYInBJ"
      },
      "outputs": [],
      "source": [
        "def make_bert_preprocessing_model(sentence_features, seq_length=224):\n",
        "    \"\"\"Returns Model mapping string features to BERT inputs.\n",
        "\n",
        "  Args:\n",
        "    sentence_features: A list with the names of string-valued features.\n",
        "    seq_length: An integer that defines the sequence length of BERT inputs.\n",
        "\n",
        "  Returns:\n",
        "    A Keras Model that can be called on a list or dict of string Tensors\n",
        "    (with the order or names, resp., given by sentence_features) and\n",
        "    returns a dict of tensors for input to BERT.\n",
        "  \"\"\"\n",
        "\n",
        "    input_segments = [\n",
        "        tf.keras.layers.Input(shape=(), dtype=tf.string, name=ft)\n",
        "        for ft in sentence_features\n",
        "    ]\n",
        "\n",
        "    # Tokenize the text to word pieces.\n",
        "    bert_preprocess = hub.load(bert_preprocess_path)\n",
        "    tokenizer = hub.KerasLayer(bert_preprocess.tokenize, name=\"tokenizer\")\n",
        "    segments = [tokenizer(s) for s in input_segments]\n",
        "\n",
        "    # Optional: Trim segments in a smart way to fit seq_length.\n",
        "    # Simple cases (like this example) can skip this step and let\n",
        "    # the next step apply a default truncation to approximately equal lengths.\n",
        "    truncated_segments = segments\n",
        "\n",
        "    # Pack inputs. The details (start/end token ids, dict of output tensors)\n",
        "    # are model-dependent, so this gets loaded from the SavedModel.\n",
        "    packer = hub.KerasLayer(\n",
        "        bert_preprocess.bert_pack_inputs,\n",
        "        arguments=dict(seq_length=seq_length),\n",
        "        name=\"packer\",\n",
        "    )\n",
        "    model_inputs = packer(truncated_segments)\n",
        "    return keras.Model(input_segments, model_inputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqW4X6onJQKQ",
        "outputId": "bbcec709-22c5-4bb5-f7e5-f230a3844266"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_1 (InputLayer)         [(None,)]                 0         \n",
            "                                                                 \n",
            " tokenizer (KerasLayer)      (None, None, None)        0         \n",
            "                                                                 \n",
            " packer (KerasLayer)         {'input_mask': (None, 22  0         \n",
            "                             4),                                 \n",
            "                              'input_word_ids': (None            \n",
            "                             , 224),                             \n",
            "                              'input_type_ids': (None            \n",
            "                             , 224)}                             \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "bert_preprocess_model = make_bert_preprocessing_model([\"text_1\"])\n",
        "bert_preprocess_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCOmGQXtJn9a",
        "outputId": "f321c927-c296-47c5-ee8e-301df1d2a8e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text 1: #SANDY ~ Prayers go out to the people affected in Hoboken, NJ http://t.co/Ax9qluv5\n",
            "Text 2: #SANDY ~ Prayers go out to the people affected in Hoboken, NJ http://t.co/Ax9qluv5\n",
            "Keys           :  ['input_mask', 'input_word_ids', 'input_type_ids']\n",
            "Shape Word Ids :  (1, 224)\n",
            "Word Ids       :  tf.Tensor(\n",
            "[  101  1001  7525  1066 12583  2175  2041  2000  1996  2111  5360  1999\n",
            "  7570  5092  7520  1010], shape=(16,), dtype=int32)\n",
            "Shape Mask     :  (1, 224)\n",
            "Input Mask     :  tf.Tensor([1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1], shape=(16,), dtype=int32)\n",
            "Shape Type Ids :  (1, 224)\n",
            "Type Ids       :  tf.Tensor([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(16,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "idx = np.random.choice(len(train_df_model))\n",
        "row = train_df_model.iloc[idx]\n",
        "sample_text_1, sample_text_2 = row[\"tweetText\"], row[\"tweetText\"]\n",
        "print(f\"Text 1: {sample_text_1}\")\n",
        "print(f\"Text 2: {sample_text_2}\")\n",
        "\n",
        "test_text = [np.array([sample_text_1])]\n",
        "text_preprocessed = bert_preprocess_model(test_text)\n",
        "\n",
        "print(\"Keys           : \", list(text_preprocessed.keys()))\n",
        "print(\"Shape Word Ids : \", text_preprocessed[\"input_word_ids\"].shape)\n",
        "print(\"Word Ids       : \", text_preprocessed[\"input_word_ids\"][0, :16])\n",
        "print(\"Shape Mask     : \", text_preprocessed[\"input_mask\"].shape)\n",
        "print(\"Input Mask     : \", text_preprocessed[\"input_mask\"][0, :16])\n",
        "print(\"Shape Type Ids : \", text_preprocessed[\"input_type_ids\"].shape)\n",
        "print(\"Type Ids       : \", text_preprocessed[\"input_type_ids\"][0, :16])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dhn-DPb7Lsb1"
      },
      "outputs": [],
      "source": [
        "def dataframe_to_dataset(dataframe):\n",
        "    columns = ['tweetText', 'image_1', 'label']\n",
        "    dataframe = dataframe[columns].copy()\n",
        "    labels = dataframe.pop(\"label\")\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "    return ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO6IRl9rkfT4"
      },
      "source": [
        "## Preprocessing utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "slef7sY9ke1l"
      },
      "outputs": [],
      "source": [
        "resize = (224, 224)\n",
        "bert_input_features = [\"input_word_ids\", \"input_type_ids\", \"input_mask\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FrTCJPUzkP3Q"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image_path):\n",
        "  extension = tf.strings.split(image_path,'.')[-1]\n",
        "  image = tf.io.read_file(image_path)\n",
        "  if extension == b\"gif\":\n",
        "    image = tf.io.decode_image(image, 3, expand_animations=False)\n",
        "  elif extension == b\"png\":\n",
        "    image = tf.image.decode_png(image, 3)\n",
        "  else:\n",
        "    image = tf.image.decode_jpeg(image, 3)\n",
        "  image = tf.image.resize(image, resize)\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IvgkLXK5k5ZX"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text_1):\n",
        "  text_1 = tf.convert_to_tensor([text_1])\n",
        "  output = bert_preprocess_model([text_1])\n",
        "  output = {feature: tf.squeeze(output[feature]) for feature in bert_input_features}\n",
        "  return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uXQHweTHpCQM"
      },
      "outputs": [],
      "source": [
        "def preprocess_text_and_image(sample):\n",
        "  image_1 = preprocess_image(sample[\"image_1\"])\n",
        "  text = preprocess_text(sample[\"tweetText\"])\n",
        "  return {\"image_1\": image_1, \"text\": text}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "C-0aLqtupoL5"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "auto = tf.data.AUTOTUNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DwL2IjrIp-Tn"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(dataframe, training=True):\n",
        "  ds = dataframe_to_dataset(dataframe)\n",
        "  if training:\n",
        "      ds = ds.shuffle(len(train_df_model))\n",
        "  ds = ds.map(lambda x, y: (preprocess_text_and_image(x), y)).cache()\n",
        "  ds = ds.batch(batch_size).prefetch(auto)\n",
        "  return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5rSseL-fqSCE"
      },
      "outputs": [],
      "source": [
        "train_ds = prepare_dataset(train_df_model)\n",
        "#validation_ds = prepare_dataset(val_df_model, False)\n",
        "test_ds = prepare_dataset(test_df_model, False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUA1fjql-NCs"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsnHD-at_70f"
      },
      "source": [
        "### Projection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "JUmnESU36Q-N"
      },
      "outputs": [],
      "source": [
        "def project_embeddings(\n",
        "    embeddings, num_projection_layers, projection_dims, dropout_rate\n",
        "):\n",
        "    projected_embeddings = keras.layers.Dense(units=projection_dims)(embeddings)\n",
        "    for _ in range(num_projection_layers):\n",
        "        x = tf.nn.gelu(projected_embeddings)\n",
        "        x = keras.layers.Dense(projection_dims)(x)\n",
        "        x = keras.layers.Dropout(dropout_rate)(x)\n",
        "        x = keras.layers.Add()([projected_embeddings, x])\n",
        "        projected_embeddings = keras.layers.LayerNormalization()(x)\n",
        "    return projected_embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEelNTYZAB0h"
      },
      "source": [
        "### Vision encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "y2ypqRWE_Oyq"
      },
      "outputs": [],
      "source": [
        "def create_vision_encoder(\n",
        "    num_projection_layers, projection_dims, dropout_rate, trainable=False\n",
        "):\n",
        "    # Load the pre-trained ResNet50V2 model to be used as the base encoder.\n",
        "    resnet_v2 = keras.applications.EfficientNetV2B3(\n",
        "        include_top=False, weights=\"imagenet\", pooling=\"avg\"\n",
        "    )\n",
        "    # Set the trainability of the base encoder.\n",
        "    for layer in resnet_v2.layers:\n",
        "        layer.trainable = trainable\n",
        "\n",
        "    # Receive the images as inputs.\n",
        "    image_1 = keras.Input(shape=(224, 224, 3), name=\"image_1\")\n",
        "    \n",
        "    # Preprocess the input image.\n",
        "    preprocessed_1 = keras.applications.resnet_v2.preprocess_input(image_1)\n",
        "    \n",
        "    # Generate the embeddings for the images using the resnet_v2 model\n",
        "    # concatenate them.\n",
        "    embeddings = resnet_v2(preprocessed_1)\n",
        "    #embeddings = keras.layers.Concatenate()([embeddings_1, embeddings_2])\n",
        "\n",
        "    # Project the embeddings produced by the model.\n",
        "    outputs = project_embeddings(\n",
        "        embeddings, num_projection_layers, projection_dims, dropout_rate\n",
        "    )\n",
        "    # Create the vision encoder model.\n",
        "    return keras.Model([image_1], outputs, name=\"vision_encoder\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtChuDndAGLm"
      },
      "source": [
        "### Text Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "UoVTKoTt_1Pv"
      },
      "outputs": [],
      "source": [
        "def create_text_encoder(\n",
        "    num_projection_layers, projection_dims, dropout_rate, trainable=False\n",
        "):\n",
        "    # Load the pre-trained BERT model to be used as the base encoder.\n",
        "    bert = hub.KerasLayer(bert_model_path, name=\"bert\",)\n",
        "    # Set the trainability of the base encoder.\n",
        "    bert.trainable = trainable\n",
        "\n",
        "    # Receive the text as inputs.\n",
        "    bert_input_features = [\"input_type_ids\", \"input_mask\", \"input_word_ids\"]\n",
        "    inputs = {\n",
        "        feature: keras.Input(shape=(224,), dtype=tf.int32, name=feature)\n",
        "        for feature in bert_input_features\n",
        "    }\n",
        "\n",
        "    # Generate embeddings for the preprocessed text using the BERT model.\n",
        "    embeddings = bert(inputs)[\"pooled_output\"]\n",
        "\n",
        "    # Project the embeddings produced by the model.\n",
        "    outputs = project_embeddings(\n",
        "        embeddings, num_projection_layers, projection_dims, dropout_rate\n",
        "    )\n",
        "    # Create the text encoder model.\n",
        "    return keras.Model(inputs, outputs, name=\"text_encoder\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF0jLUzqjwFv"
      },
      "source": [
        "### Multi Head Attention Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "UX52i1Pj4piV"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att = keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [keras.layers.Dense(ff_dim, activation=\"relu\"), keras.layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = keras.layers.Dropout(rate)\n",
        "        self.dropout2 = keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, y, training):\n",
        "        attn_output = self.att(x, y)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ugj-e4g8AWOp"
      },
      "source": [
        "## MultiModal model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1RjaNwDnANoc"
      },
      "outputs": [],
      "source": [
        "def create_multimodal_model(\n",
        "    num_projection_layers=0,\n",
        "    projection_dims=224,\n",
        "    dropout_rate=0.1,\n",
        "    vision_trainable=False,\n",
        "    text_trainable=False,\n",
        "    attention=False\n",
        "):\n",
        "    # Receive the images as inputs.\n",
        "    image_1 = keras.Input(shape=(224, 224, 3), name=\"image_1\")\n",
        "    \n",
        "    # Receive the text as inputs.\n",
        "    bert_input_features = [\"input_type_ids\", \"input_mask\", \"input_word_ids\"]\n",
        "    text_inputs = {\n",
        "        feature: keras.Input(shape=(224,), dtype=tf.int32, name=feature)\n",
        "        for feature in bert_input_features\n",
        "    }\n",
        "\n",
        "    # Create the encoders.\n",
        "    vision_encoder = create_vision_encoder(\n",
        "        num_projection_layers, projection_dims, dropout_rate, vision_trainable\n",
        "    )\n",
        "    text_encoder = create_text_encoder(\n",
        "        num_projection_layers, projection_dims, dropout_rate, text_trainable\n",
        "    )\n",
        "\n",
        "    # Fetch the embedding projections.\n",
        "    vision_projections = vision_encoder([image_1])\n",
        "    vision_projections = keras.layers.Dropout(dropout_rate)(vision_projections)\n",
        "    text_projections = text_encoder(text_inputs)\n",
        "    text_projections = keras.layers.Dropout(dropout_rate)(text_projections)\n",
        "    \n",
        "    # Cross-attention.\n",
        "    if attention:\n",
        "      transformer_block = TransformerBlock(projection_dims, 4, projection_dims)\n",
        "      x = transformer_block(tf.expand_dims(vision_projections, -1), tf.expand_dims(text_projections, -1))\n",
        "      x = tf.keras.layers.Flatten()(x)\n",
        "      \n",
        "    # Concatenate the projections and pass through the classification layer.\n",
        "    concatenated = keras.layers.Concatenate()([vision_projections, text_projections])\n",
        "    if attention:\n",
        "        concatenated = keras.layers.Concatenate()([concatenated, x])\n",
        "        #x = tf.keras.layers.Flatten(x)\n",
        "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(concatenated)\n",
        "    return keras.Model([image_1, text_inputs], outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "HYAqM03bYqpj"
      },
      "outputs": [],
      "source": [
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "metrics= [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall')\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "lzh_oeuuZVrA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvh6vbUTXRRs"
      },
      "source": [
        "## Final Multimodal model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "iMyfwuhtXQRJ"
      },
      "outputs": [],
      "source": [
        "def multimodal_model(X_train, y_train, X_test, y_test, params):\n",
        "  train_ds = prepare_dataset(train_df_model)\n",
        "  test_ds = prepare_dataset(test_df_model, False)\n",
        "  model = create_multimodal_model(params['num_projection_layers'],\n",
        "    params['projection_dims'],\n",
        "    params['dropout_rate'],\n",
        "    params['vision_trainable'],\n",
        "    params['text_trainable'],\n",
        "    params['attention'])\n",
        "  model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(params['lr']), loss=loss, metrics=metrics\n",
        "  )\n",
        "  history = model.fit(\n",
        "      train_ds, validation_data=test_ds, \n",
        "      epochs=params['epochs'], batch_size=params['batch_size'])\n",
        "  return history, model\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hLDJku6bY9O"
      },
      "outputs": [],
      "source": [
        "params = {\n",
        "    'num_projection_layers' : [0],\n",
        "    'projection_dims' : [128, 224],\n",
        "    'dropout_rate' : [0.1, 0.2],\n",
        "    'vision_trainable' : [False],\n",
        "    'text_trainable' : [False],\n",
        "    'attention' : [True],\n",
        "    'lr' : [0.001, 0.0005],\n",
        "    'epochs' : [10],\n",
        "    'batch_size' : [32, 64]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhrpIETIevhH",
        "outputId": "1634090f-eafd-401d-c9d7-3a77066d78d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/16 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'num_projection_layers': 0, 'projection_dims': 128, 'dropout_rate': 0.1, 'vision_trainable': False, 'text_trainable': False, 'attention': True, 'lr': 0.001, 'epochs': 10, 'batch_size': 32}\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-b3_notop.h5\n",
            "52606240/52606240 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "446/446 [==============================] - 202s 378ms/step - loss: 0.5066 - accuracy: 0.7622 - precision: 0.6845 - recall: 0.5729 - val_loss: 0.5975 - val_accuracy: 0.6875 - val_precision: 0.9128 - val_recall: 0.5551\n",
            "Epoch 2/10\n",
            "446/446 [==============================] - 58s 130ms/step - loss: 0.3527 - accuracy: 0.8516 - precision: 0.8133 - recall: 0.7380 - val_loss: 0.4931 - val_accuracy: 0.8565 - val_precision: 0.9175 - val_recall: 0.8476\n",
            "Epoch 3/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.3062 - accuracy: 0.8730 - precision: 0.8384 - recall: 0.7814 - val_loss: 0.4220 - val_accuracy: 0.8492 - val_precision: 0.8707 - val_recall: 0.8923\n",
            "Epoch 4/10\n",
            "446/446 [==============================] - 58s 130ms/step - loss: 0.2896 - accuracy: 0.8785 - precision: 0.8472 - recall: 0.7890 - val_loss: 0.4207 - val_accuracy: 0.8799 - val_precision: 0.9288 - val_recall: 0.8757\n",
            "Epoch 5/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2693 - accuracy: 0.8888 - precision: 0.8605 - recall: 0.8075 - val_loss: 0.3800 - val_accuracy: 0.8430 - val_precision: 0.8436 - val_recall: 0.9205\n",
            "Epoch 6/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2618 - accuracy: 0.8928 - precision: 0.8648 - recall: 0.8161 - val_loss: 0.3861 - val_accuracy: 0.8768 - val_precision: 0.9262 - val_recall: 0.8732\n",
            "Epoch 7/10\n",
            "446/446 [==============================] - 58s 130ms/step - loss: 0.2460 - accuracy: 0.9006 - precision: 0.8768 - recall: 0.8273 - val_loss: 0.3849 - val_accuracy: 0.8586 - val_precision: 0.8761 - val_recall: 0.9022\n",
            "Epoch 8/10\n",
            "446/446 [==============================] - 58s 130ms/step - loss: 0.2321 - accuracy: 0.9083 - precision: 0.8875 - recall: 0.8398 - val_loss: 0.3856 - val_accuracy: 0.8757 - val_precision: 0.9231 - val_recall: 0.8749\n",
            "Epoch 9/10\n",
            "446/446 [==============================] - 58s 130ms/step - loss: 0.2328 - accuracy: 0.9090 - precision: 0.8880 - recall: 0.8418 - val_loss: 0.4118 - val_accuracy: 0.8274 - val_precision: 0.8229 - val_recall: 0.9238\n",
            "Epoch 10/10\n",
            "446/446 [==============================] - 58s 130ms/step - loss: 0.2254 - accuracy: 0.9088 - precision: 0.8874 - recall: 0.8416 - val_loss: 0.3992 - val_accuracy: 0.8461 - val_precision: 0.8659 - val_recall: 0.8931\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  6%|▋         | 1/16 [12:16<3:04:08, 736.55s/it]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'num_projection_layers': 0, 'projection_dims': 128, 'dropout_rate': 0.1, 'vision_trainable': False, 'text_trainable': False, 'attention': True, 'lr': 0.001, 'epochs': 10, 'batch_size': 64}\n",
            "Epoch 1/10\n",
            "446/446 [==============================] - 105s 199ms/step - loss: 0.5549 - accuracy: 0.7587 - precision: 0.7032 - recall: 0.6252 - val_loss: 0.4312 - val_accuracy: 0.8471 - val_precision: 0.8708 - val_recall: 0.8882\n",
            "Epoch 2/10\n",
            "446/446 [==============================] - 59s 131ms/step - loss: 0.3603 - accuracy: 0.8478 - precision: 0.8063 - recall: 0.7339 - val_loss: 0.5696 - val_accuracy: 0.7410 - val_precision: 0.9426 - val_recall: 0.6255\n",
            "Epoch 3/10\n",
            "446/446 [==============================] - 58s 130ms/step - loss: 0.3073 - accuracy: 0.8741 - precision: 0.8425 - recall: 0.7798 - val_loss: 0.4728 - val_accuracy: 0.8664 - val_precision: 0.9414 - val_recall: 0.8393\n",
            "Epoch 4/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2916 - accuracy: 0.8799 - precision: 0.8477 - recall: 0.7935 - val_loss: 0.4790 - val_accuracy: 0.8528 - val_precision: 0.9494 - val_recall: 0.8086\n",
            "Epoch 5/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2732 - accuracy: 0.8880 - precision: 0.8610 - recall: 0.8043 - val_loss: 0.4046 - val_accuracy: 0.8794 - val_precision: 0.9333 - val_recall: 0.8699\n",
            "Epoch 6/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2642 - accuracy: 0.8929 - precision: 0.8664 - recall: 0.8143 - val_loss: 0.3991 - val_accuracy: 0.8820 - val_precision: 0.9554 - val_recall: 0.8517\n",
            "Epoch 7/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2510 - accuracy: 0.8977 - precision: 0.8726 - recall: 0.8228 - val_loss: 0.5536 - val_accuracy: 0.8040 - val_precision: 0.9591 - val_recall: 0.7183\n",
            "Epoch 8/10\n",
            "446/446 [==============================] - 58s 130ms/step - loss: 0.2410 - accuracy: 0.9030 - precision: 0.8800 - recall: 0.8314 - val_loss: 0.4397 - val_accuracy: 0.8664 - val_precision: 0.9559 - val_recall: 0.8252\n",
            "Epoch 9/10\n",
            "446/446 [==============================] - 58s 130ms/step - loss: 0.2329 - accuracy: 0.9079 - precision: 0.8862 - recall: 0.8402 - val_loss: 0.4188 - val_accuracy: 0.8747 - val_precision: 0.9557 - val_recall: 0.8393\n",
            "Epoch 10/10\n",
            "446/446 [==============================] - 58s 130ms/step - loss: 0.2268 - accuracy: 0.9093 - precision: 0.8854 - recall: 0.8459 - val_loss: 0.5224 - val_accuracy: 0.8378 - val_precision: 0.9580 - val_recall: 0.7755\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 12%|█▎        | 2/16 [22:56<2:38:33, 679.55s/it]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'num_projection_layers': 0, 'projection_dims': 128, 'dropout_rate': 0.1, 'vision_trainable': False, 'text_trainable': False, 'attention': True, 'lr': 0.0005, 'epochs': 10, 'batch_size': 32}\n",
            "Epoch 1/10\n",
            "446/446 [==============================] - 105s 197ms/step - loss: 0.5158 - accuracy: 0.7640 - precision: 0.7548 - recall: 0.5556 - val_loss: 0.4946 - val_accuracy: 0.8237 - val_precision: 0.9483 - val_recall: 0.7606\n",
            "Epoch 2/10\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 0.3729 - accuracy: 0.8418 - precision: 0.8053 - recall: 0.7123 - val_loss: 0.6149 - val_accuracy: 0.6583 - val_precision: 0.9379 - val_recall: 0.4880\n",
            "Epoch 3/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.3308 - accuracy: 0.8618 - precision: 0.8260 - recall: 0.7580 - val_loss: 0.4042 - val_accuracy: 0.8653 - val_precision: 0.8930 - val_recall: 0.8923\n",
            "Epoch 4/10\n",
            "446/446 [==============================] - 59s 131ms/step - loss: 0.2989 - accuracy: 0.8782 - precision: 0.8497 - recall: 0.7849 - val_loss: 0.4051 - val_accuracy: 0.8596 - val_precision: 0.8850 - val_recall: 0.8923\n",
            "Epoch 5/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2804 - accuracy: 0.8880 - precision: 0.8616 - recall: 0.8035 - val_loss: 0.4642 - val_accuracy: 0.8632 - val_precision: 0.9453 - val_recall: 0.8302\n",
            "Epoch 6/10\n",
            "446/446 [==============================] - 58s 130ms/step - loss: 0.2768 - accuracy: 0.8867 - precision: 0.8576 - recall: 0.8043 - val_loss: 0.3973 - val_accuracy: 0.8700 - val_precision: 0.9038 - val_recall: 0.8873\n",
            "Epoch 7/10\n",
            "446/446 [==============================] - 58s 130ms/step - loss: 0.2616 - accuracy: 0.8951 - precision: 0.8705 - recall: 0.8167 - val_loss: 0.3844 - val_accuracy: 0.8544 - val_precision: 0.8693 - val_recall: 0.9039\n",
            "Epoch 8/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2468 - accuracy: 0.9017 - precision: 0.8786 - recall: 0.8290 - val_loss: 0.3896 - val_accuracy: 0.8742 - val_precision: 0.9199 - val_recall: 0.8757\n",
            "Epoch 9/10\n",
            "446/446 [==============================] - 58s 130ms/step - loss: 0.2348 - accuracy: 0.9031 - precision: 0.8791 - recall: 0.8330 - val_loss: 0.3747 - val_accuracy: 0.8705 - val_precision: 0.9066 - val_recall: 0.8848\n",
            "Epoch 10/10\n",
            "446/446 [==============================] - 58s 130ms/step - loss: 0.2409 - accuracy: 0.9023 - precision: 0.8791 - recall: 0.8302 - val_loss: 0.3703 - val_accuracy: 0.8612 - val_precision: 0.8827 - val_recall: 0.8981\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 19%|█▉        | 3/16 [34:26<2:28:19, 684.59s/it]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'num_projection_layers': 0, 'projection_dims': 128, 'dropout_rate': 0.1, 'vision_trainable': False, 'text_trainable': False, 'attention': True, 'lr': 0.0005, 'epochs': 10, 'batch_size': 64}\n",
            "Epoch 1/10\n",
            "446/446 [==============================] - 104s 199ms/step - loss: 0.5142 - accuracy: 0.7675 - precision: 0.7405 - recall: 0.5920 - val_loss: 0.4804 - val_accuracy: 0.8268 - val_precision: 0.9543 - val_recall: 0.7606\n",
            "Epoch 2/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.3701 - accuracy: 0.8467 - precision: 0.8102 - recall: 0.7240 - val_loss: 0.6217 - val_accuracy: 0.6667 - val_precision: 0.9408 - val_recall: 0.5004\n",
            "Epoch 3/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.3371 - accuracy: 0.8603 - precision: 0.8242 - recall: 0.7549 - val_loss: 0.5257 - val_accuracy: 0.8222 - val_precision: 0.9482 - val_recall: 0.7581\n",
            "Epoch 4/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.3088 - accuracy: 0.8740 - precision: 0.8407 - recall: 0.7821 - val_loss: 0.7893 - val_accuracy: 0.5445 - val_precision: 0.9254 - val_recall: 0.2983\n",
            "Epoch 5/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2843 - accuracy: 0.8855 - precision: 0.8561 - recall: 0.8018 - val_loss: 0.6045 - val_accuracy: 0.6921 - val_precision: 0.9437 - val_recall: 0.5418\n",
            "Epoch 6/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2722 - accuracy: 0.8891 - precision: 0.8591 - recall: 0.8106 - val_loss: 0.6634 - val_accuracy: 0.6547 - val_precision: 0.9400 - val_recall: 0.4805\n",
            "Epoch 7/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2657 - accuracy: 0.8933 - precision: 0.8686 - recall: 0.8128 - val_loss: 0.6604 - val_accuracy: 0.6823 - val_precision: 0.9515 - val_recall: 0.5203\n",
            "Epoch 8/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2528 - accuracy: 0.8989 - precision: 0.8725 - recall: 0.8271 - val_loss: 0.5019 - val_accuracy: 0.8440 - val_precision: 0.9595 - val_recall: 0.7846\n",
            "Epoch 9/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2429 - accuracy: 0.9026 - precision: 0.8784 - recall: 0.8320 - val_loss: 0.6274 - val_accuracy: 0.7114 - val_precision: 0.9515 - val_recall: 0.5692\n",
            "Epoch 10/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2291 - accuracy: 0.9111 - precision: 0.8920 - recall: 0.8436 - val_loss: 0.5077 - val_accuracy: 0.8445 - val_precision: 0.9586 - val_recall: 0.7862\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 25%|██▌       | 4/16 [45:06<2:13:20, 666.70s/it]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'num_projection_layers': 0, 'projection_dims': 128, 'dropout_rate': 0.2, 'vision_trainable': False, 'text_trainable': False, 'attention': True, 'lr': 0.001, 'epochs': 10, 'batch_size': 32}\n",
            "Epoch 1/10\n",
            "446/446 [==============================] - 105s 199ms/step - loss: 0.4883 - accuracy: 0.7828 - precision: 0.7603 - recall: 0.6206 - val_loss: 0.4560 - val_accuracy: 0.8409 - val_precision: 0.8867 - val_recall: 0.8558\n",
            "Epoch 2/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.3638 - accuracy: 0.8461 - precision: 0.8022 - recall: 0.7335 - val_loss: 0.4223 - val_accuracy: 0.8388 - val_precision: 0.8474 - val_recall: 0.9064\n",
            "Epoch 3/10\n",
            "446/446 [==============================] - 58s 130ms/step - loss: 0.3097 - accuracy: 0.8709 - precision: 0.8397 - recall: 0.7723 - val_loss: 0.4249 - val_accuracy: 0.8336 - val_precision: 0.8347 - val_recall: 0.9163\n",
            "Epoch 4/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2926 - accuracy: 0.8825 - precision: 0.8514 - recall: 0.7976 - val_loss: 0.3884 - val_accuracy: 0.8523 - val_precision: 0.8575 - val_recall: 0.9171\n",
            "Epoch 5/10\n",
            "446/446 [==============================] - 58s 130ms/step - loss: 0.2697 - accuracy: 0.8895 - precision: 0.8626 - recall: 0.8075 - val_loss: 0.4458 - val_accuracy: 0.8570 - val_precision: 0.9252 - val_recall: 0.8401\n",
            "Epoch 6/10\n",
            "446/446 [==============================] - 58s 130ms/step - loss: 0.2661 - accuracy: 0.8904 - precision: 0.8617 - recall: 0.8118 - val_loss: 0.3891 - val_accuracy: 0.8554 - val_precision: 0.8994 - val_recall: 0.8666\n",
            "Epoch 7/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2530 - accuracy: 0.8996 - precision: 0.8756 - recall: 0.8253 - val_loss: 0.3943 - val_accuracy: 0.8606 - val_precision: 0.9051 - val_recall: 0.8691\n",
            "Epoch 8/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2370 - accuracy: 0.9053 - precision: 0.8835 - recall: 0.8349 - val_loss: 0.3917 - val_accuracy: 0.8742 - val_precision: 0.9229 - val_recall: 0.8724\n",
            "Epoch 9/10\n",
            "446/446 [==============================] - 58s 130ms/step - loss: 0.2300 - accuracy: 0.9068 - precision: 0.8873 - recall: 0.8351 - val_loss: 0.3674 - val_accuracy: 0.8679 - val_precision: 0.9055 - val_recall: 0.8815\n",
            "Epoch 10/10\n",
            "446/446 [==============================] - 58s 130ms/step - loss: 0.2346 - accuracy: 0.9067 - precision: 0.8853 - recall: 0.8373 - val_loss: 0.3969 - val_accuracy: 0.8476 - val_precision: 0.8783 - val_recall: 0.8790\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 31%|███▏      | 5/16 [55:45<2:00:23, 656.70s/it]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'num_projection_layers': 0, 'projection_dims': 128, 'dropout_rate': 0.2, 'vision_trainable': False, 'text_trainable': False, 'attention': True, 'lr': 0.001, 'epochs': 10, 'batch_size': 64}\n",
            "Epoch 1/10\n",
            "446/446 [==============================] - 103s 196ms/step - loss: 0.5113 - accuracy: 0.7766 - precision: 0.7406 - recall: 0.6288 - val_loss: 1.0284 - val_accuracy: 0.3859 - val_precision: 0.6970 - val_recall: 0.0381\n",
            "Epoch 2/10\n",
            "446/446 [==============================] - 59s 131ms/step - loss: 0.3460 - accuracy: 0.8530 - precision: 0.8157 - recall: 0.7399 - val_loss: 0.9610 - val_accuracy: 0.4056 - val_precision: 0.7712 - val_recall: 0.0754\n",
            "Epoch 3/10\n",
            "446/446 [==============================] - 58s 130ms/step - loss: 0.3099 - accuracy: 0.8725 - precision: 0.8368 - recall: 0.7819 - val_loss: 0.8831 - val_accuracy: 0.4982 - val_precision: 0.9116 - val_recall: 0.2220\n",
            "Epoch 4/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2862 - accuracy: 0.8858 - precision: 0.8566 - recall: 0.8024 - val_loss: 1.2378 - val_accuracy: 0.3801 - val_precision: 0.6596 - val_recall: 0.0257\n",
            "Epoch 5/10\n",
            "446/446 [==============================] - 58s 130ms/step - loss: 0.2811 - accuracy: 0.8839 - precision: 0.8522 - recall: 0.8016 - val_loss: 0.7178 - val_accuracy: 0.6100 - val_precision: 0.9386 - val_recall: 0.4051\n",
            "Epoch 6/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2625 - accuracy: 0.8921 - precision: 0.8643 - recall: 0.8141 - val_loss: 0.4857 - val_accuracy: 0.8336 - val_precision: 0.9558 - val_recall: 0.7705\n",
            "Epoch 7/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2489 - accuracy: 0.8962 - precision: 0.8684 - recall: 0.8230 - val_loss: 0.6361 - val_accuracy: 0.6994 - val_precision: 0.9512 - val_recall: 0.5493\n",
            "Epoch 8/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2485 - accuracy: 0.9005 - precision: 0.8758 - recall: 0.8281 - val_loss: 0.5553 - val_accuracy: 0.8050 - val_precision: 0.9581 - val_recall: 0.7208\n",
            "Epoch 9/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2328 - accuracy: 0.9070 - precision: 0.8856 - recall: 0.8379 - val_loss: 0.8487 - val_accuracy: 0.5850 - val_precision: 0.9455 - val_recall: 0.3596\n",
            "Epoch 10/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2398 - accuracy: 0.9048 - precision: 0.8812 - recall: 0.8361 - val_loss: 0.5272 - val_accuracy: 0.8190 - val_precision: 0.9574 - val_recall: 0.7448\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 38%|███▊      | 6/16 [1:07:16<1:51:25, 668.54s/it]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'num_projection_layers': 0, 'projection_dims': 128, 'dropout_rate': 0.2, 'vision_trainable': False, 'text_trainable': False, 'attention': True, 'lr': 0.0005, 'epochs': 10, 'batch_size': 32}\n",
            "Epoch 1/10\n",
            "446/446 [==============================] - 103s 195ms/step - loss: 0.5425 - accuracy: 0.7415 - precision: 0.7098 - recall: 0.5339 - val_loss: 0.5430 - val_accuracy: 0.8144 - val_precision: 0.9550 - val_recall: 0.7390\n",
            "Epoch 2/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.3829 - accuracy: 0.8344 - precision: 0.7962 - recall: 0.6970 - val_loss: 0.5500 - val_accuracy: 0.7925 - val_precision: 0.9430 - val_recall: 0.7125\n",
            "Epoch 3/10\n",
            "446/446 [==============================] - 58s 130ms/step - loss: 0.3379 - accuracy: 0.8573 - precision: 0.8214 - recall: 0.7480 - val_loss: 0.7002 - val_accuracy: 0.5491 - val_precision: 0.9146 - val_recall: 0.3107\n",
            "Epoch 4/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.3171 - accuracy: 0.8671 - precision: 0.8359 - recall: 0.7635 - val_loss: 0.6239 - val_accuracy: 0.6594 - val_precision: 0.9381 - val_recall: 0.4896\n",
            "Epoch 5/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2927 - accuracy: 0.8789 - precision: 0.8493 - recall: 0.7880 - val_loss: 0.5979 - val_accuracy: 0.7223 - val_precision: 0.9481 - val_recall: 0.5899\n",
            "Epoch 6/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2788 - accuracy: 0.8861 - precision: 0.8602 - recall: 0.7988 - val_loss: 0.4941 - val_accuracy: 0.8471 - val_precision: 0.9515 - val_recall: 0.7970\n",
            "Epoch 7/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2618 - accuracy: 0.8926 - precision: 0.8650 - recall: 0.8151 - val_loss: 0.5971 - val_accuracy: 0.7145 - val_precision: 0.9434 - val_recall: 0.5800\n",
            "Epoch 8/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2571 - accuracy: 0.8958 - precision: 0.8721 - recall: 0.8171 - val_loss: 0.5150 - val_accuracy: 0.8383 - val_precision: 0.9534 - val_recall: 0.7804\n",
            "Epoch 9/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2474 - accuracy: 0.9013 - precision: 0.8763 - recall: 0.8304 - val_loss: 0.4090 - val_accuracy: 0.8752 - val_precision: 0.9448 - val_recall: 0.8509\n",
            "Epoch 10/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2477 - accuracy: 0.9012 - precision: 0.8754 - recall: 0.8310 - val_loss: 0.5500 - val_accuracy: 0.8040 - val_precision: 0.9560 - val_recall: 0.7208\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 44%|████▍     | 7/16 [1:17:55<1:38:49, 658.87s/it]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'num_projection_layers': 0, 'projection_dims': 128, 'dropout_rate': 0.2, 'vision_trainable': False, 'text_trainable': False, 'attention': True, 'lr': 0.0005, 'epochs': 10, 'batch_size': 64}\n",
            "Epoch 1/10\n",
            "446/446 [==============================] - 104s 199ms/step - loss: 0.5269 - accuracy: 0.7527 - precision: 0.7386 - recall: 0.5345 - val_loss: 0.3947 - val_accuracy: 0.8570 - val_precision: 0.8956 - val_recall: 0.8741\n",
            "Epoch 2/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.3759 - accuracy: 0.8378 - precision: 0.8003 - recall: 0.7044 - val_loss: 0.4750 - val_accuracy: 0.8560 - val_precision: 0.9463 - val_recall: 0.8169\n",
            "Epoch 3/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.3409 - accuracy: 0.8581 - precision: 0.8215 - recall: 0.7507 - val_loss: 0.4527 - val_accuracy: 0.8674 - val_precision: 0.9440 - val_recall: 0.8384\n",
            "Epoch 4/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.3182 - accuracy: 0.8661 - precision: 0.8275 - recall: 0.7717 - val_loss: 0.4802 - val_accuracy: 0.8653 - val_precision: 0.9413 - val_recall: 0.8376\n",
            "Epoch 5/10\n",
            "446/446 [==============================] - 59s 131ms/step - loss: 0.2974 - accuracy: 0.8790 - precision: 0.8491 - recall: 0.7884 - val_loss: 0.4380 - val_accuracy: 0.8783 - val_precision: 0.9340 - val_recall: 0.8674\n",
            "Epoch 6/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2779 - accuracy: 0.8843 - precision: 0.8539 - recall: 0.8008 - val_loss: 0.3897 - val_accuracy: 0.8570 - val_precision: 0.8789 - val_recall: 0.8956\n",
            "Epoch 7/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2641 - accuracy: 0.8938 - precision: 0.8695 - recall: 0.8135 - val_loss: 0.4234 - val_accuracy: 0.8804 - val_precision: 0.9445 - val_recall: 0.8600\n",
            "Epoch 8/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2572 - accuracy: 0.8961 - precision: 0.8714 - recall: 0.8190 - val_loss: 0.3805 - val_accuracy: 0.8851 - val_precision: 0.9347 - val_recall: 0.8782\n",
            "Epoch 9/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2479 - accuracy: 0.9030 - precision: 0.8785 - recall: 0.8332 - val_loss: 0.4441 - val_accuracy: 0.8664 - val_precision: 0.9585 - val_recall: 0.8227\n",
            "Epoch 10/10\n",
            "446/446 [==============================] - 58s 131ms/step - loss: 0.2408 - accuracy: 0.9003 - precision: 0.8730 - recall: 0.8312 - val_loss: 0.3642 - val_accuracy: 0.8778 - val_precision: 0.9233 - val_recall: 0.8782\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 50%|█████     | 8/16 [1:28:35<1:27:03, 652.94s/it]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'num_projection_layers': 0, 'projection_dims': 224, 'dropout_rate': 0.1, 'vision_trainable': False, 'text_trainable': False, 'attention': True, 'lr': 0.001, 'epochs': 10, 'batch_size': 32}\n",
            "Epoch 1/10\n",
            "446/446 [==============================] - 105s 199ms/step - loss: 0.8473 - accuracy: 0.7441 - precision: 0.6773 - recall: 0.6158 - val_loss: 0.4155 - val_accuracy: 0.8523 - val_precision: 0.8713 - val_recall: 0.8973\n",
            "Epoch 2/10\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.3707 - accuracy: 0.8413 - precision: 0.7907 - recall: 0.7325 - val_loss: 0.5468 - val_accuracy: 0.7795 - val_precision: 0.9516 - val_recall: 0.6835\n",
            "Epoch 3/10\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 0.3167 - accuracy: 0.8672 - precision: 0.8266 - recall: 0.7768 - val_loss: 0.5520 - val_accuracy: 0.7988 - val_precision: 0.9556 - val_recall: 0.7125\n",
            "Epoch 4/10\n",
            "446/446 [==============================] - 63s 140ms/step - loss: 0.3118 - accuracy: 0.8691 - precision: 0.8267 - recall: 0.7837 - val_loss: 0.4496 - val_accuracy: 0.8518 - val_precision: 0.9450 - val_recall: 0.8111\n",
            "Epoch 5/10\n",
            "446/446 [==============================] - 63s 141ms/step - loss: 0.2673 - accuracy: 0.8896 - precision: 0.8600 - recall: 0.8112 - val_loss: 0.5876 - val_accuracy: 0.7681 - val_precision: 0.9546 - val_recall: 0.6620\n",
            "Epoch 6/10\n",
            "446/446 [==============================] - 63s 141ms/step - loss: 0.2548 - accuracy: 0.8968 - precision: 0.8704 - recall: 0.8226 - val_loss: 0.8674 - val_accuracy: 0.5705 - val_precision: 0.9339 - val_recall: 0.3397\n",
            "Epoch 7/10\n",
            "446/446 [==============================] - 63s 141ms/step - loss: 0.2474 - accuracy: 0.8986 - precision: 0.8703 - recall: 0.8287 - val_loss: 0.6804 - val_accuracy: 0.7426 - val_precision: 0.9576 - val_recall: 0.6172\n",
            "Epoch 8/10\n",
            "446/446 [==============================] - 63s 141ms/step - loss: 0.2352 - accuracy: 0.9025 - precision: 0.8758 - recall: 0.8351 - val_loss: 0.5202 - val_accuracy: 0.8305 - val_precision: 0.9603 - val_recall: 0.7614\n",
            "Epoch 9/10\n",
            "446/446 [==============================] - 63s 141ms/step - loss: 0.2456 - accuracy: 0.9006 - precision: 0.8747 - recall: 0.8300 - val_loss: 0.4873 - val_accuracy: 0.8492 - val_precision: 0.9590 - val_recall: 0.7937\n",
            "Epoch 10/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.2199 - accuracy: 0.9116 - precision: 0.8888 - recall: 0.8491 - val_loss: 0.6639 - val_accuracy: 0.7499 - val_precision: 0.9630 - val_recall: 0.6255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 56%|█████▋    | 9/16 [1:41:06<1:19:43, 683.40s/it]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'num_projection_layers': 0, 'projection_dims': 224, 'dropout_rate': 0.1, 'vision_trainable': False, 'text_trainable': False, 'attention': True, 'lr': 0.001, 'epochs': 10, 'batch_size': 64}\n",
            "Epoch 1/10\n",
            "446/446 [==============================] - 106s 202ms/step - loss: 0.8374 - accuracy: 0.7182 - precision: 0.6447 - recall: 0.5658 - val_loss: 3.1203 - val_accuracy: 0.3729 - val_precision: 1.0000 - val_recall: 8.2850e-04\n",
            "Epoch 2/10\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 0.3907 - accuracy: 0.8419 - precision: 0.7925 - recall: 0.7321 - val_loss: 0.5958 - val_accuracy: 0.6927 - val_precision: 0.9254 - val_recall: 0.5551\n",
            "Epoch 3/10\n",
            "446/446 [==============================] - 63s 141ms/step - loss: 0.3211 - accuracy: 0.8660 - precision: 0.8252 - recall: 0.7745 - val_loss: 0.4384 - val_accuracy: 0.8664 - val_precision: 0.9012 - val_recall: 0.8840\n",
            "Epoch 4/10\n",
            "446/446 [==============================] - 63s 141ms/step - loss: 0.2996 - accuracy: 0.8761 - precision: 0.8437 - recall: 0.7855 - val_loss: 0.4430 - val_accuracy: 0.8029 - val_precision: 0.7903 - val_recall: 0.9337\n",
            "Epoch 5/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.2798 - accuracy: 0.8840 - precision: 0.8490 - recall: 0.8061 - val_loss: 0.4016 - val_accuracy: 0.8617 - val_precision: 0.8918 - val_recall: 0.8873\n",
            "Epoch 6/10\n",
            "446/446 [==============================] - 63s 141ms/step - loss: 0.2742 - accuracy: 0.8863 - precision: 0.8540 - recall: 0.8075 - val_loss: 0.4502 - val_accuracy: 0.8669 - val_precision: 0.9272 - val_recall: 0.8550\n",
            "Epoch 7/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.2475 - accuracy: 0.8985 - precision: 0.8712 - recall: 0.8273 - val_loss: 0.4061 - val_accuracy: 0.8487 - val_precision: 0.8754 - val_recall: 0.8848\n",
            "Epoch 8/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.2443 - accuracy: 0.9029 - precision: 0.8769 - recall: 0.8351 - val_loss: 0.3903 - val_accuracy: 0.8580 - val_precision: 0.8911 - val_recall: 0.8815\n",
            "Epoch 9/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.2353 - accuracy: 0.9062 - precision: 0.8815 - recall: 0.8404 - val_loss: 0.4554 - val_accuracy: 0.8627 - val_precision: 0.9478 - val_recall: 0.8268\n",
            "Epoch 10/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.2242 - accuracy: 0.9117 - precision: 0.8902 - recall: 0.8479 - val_loss: 0.4946 - val_accuracy: 0.8523 - val_precision: 0.9485 - val_recall: 0.8086\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 62%|██████▎   | 10/16 [1:52:30<1:08:22, 683.71s/it]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'num_projection_layers': 0, 'projection_dims': 224, 'dropout_rate': 0.1, 'vision_trainable': False, 'text_trainable': False, 'attention': True, 'lr': 0.0005, 'epochs': 10, 'batch_size': 32}\n",
            "Epoch 1/10\n",
            "446/446 [==============================] - 108s 206ms/step - loss: 0.5413 - accuracy: 0.7583 - precision: 0.7266 - recall: 0.5774 - val_loss: 0.6077 - val_accuracy: 0.7967 - val_precision: 0.9543 - val_recall: 0.7100\n",
            "Epoch 2/10\n",
            "446/446 [==============================] - 62s 139ms/step - loss: 0.4017 - accuracy: 0.8264 - precision: 0.7735 - recall: 0.7005 - val_loss: 0.6652 - val_accuracy: 0.6308 - val_precision: 0.9307 - val_recall: 0.4449\n",
            "Epoch 3/10\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 0.3623 - accuracy: 0.8461 - precision: 0.7971 - recall: 0.7411 - val_loss: 0.6423 - val_accuracy: 0.6958 - val_precision: 0.9430 - val_recall: 0.5485\n",
            "Epoch 4/10\n",
            "446/446 [==============================] - 63s 141ms/step - loss: 0.3296 - accuracy: 0.8599 - precision: 0.8143 - recall: 0.7678 - val_loss: 0.4678 - val_accuracy: 0.8528 - val_precision: 0.9358 - val_recall: 0.8219\n",
            "Epoch 5/10\n",
            "446/446 [==============================] - 63s 141ms/step - loss: 0.3100 - accuracy: 0.8709 - precision: 0.8309 - recall: 0.7845 - val_loss: 0.4964 - val_accuracy: 0.8331 - val_precision: 0.9386 - val_recall: 0.7854\n",
            "Epoch 6/10\n",
            "446/446 [==============================] - 63s 141ms/step - loss: 0.3165 - accuracy: 0.8684 - precision: 0.8212 - recall: 0.7894 - val_loss: 0.9561 - val_accuracy: 0.5398 - val_precision: 0.9305 - val_recall: 0.2883\n",
            "Epoch 7/10\n",
            "446/446 [==============================] - 63s 141ms/step - loss: 0.2788 - accuracy: 0.8872 - precision: 0.8492 - recall: 0.8171 - val_loss: 0.4207 - val_accuracy: 0.8523 - val_precision: 0.9383 - val_recall: 0.8186\n",
            "Epoch 8/10\n",
            "446/446 [==============================] - 63s 141ms/step - loss: 0.2859 - accuracy: 0.8861 - precision: 0.8497 - recall: 0.8126 - val_loss: 0.5630 - val_accuracy: 0.8144 - val_precision: 0.9560 - val_recall: 0.7382\n",
            "Epoch 9/10\n",
            "446/446 [==============================] - 63s 141ms/step - loss: 0.2643 - accuracy: 0.8934 - precision: 0.8623 - recall: 0.8212 - val_loss: 0.3981 - val_accuracy: 0.8653 - val_precision: 0.9325 - val_recall: 0.8467\n",
            "Epoch 10/10\n",
            "446/446 [==============================] - 63s 141ms/step - loss: 0.2635 - accuracy: 0.8948 - precision: 0.8599 - recall: 0.8294 - val_loss: 0.5876 - val_accuracy: 0.8092 - val_precision: 0.9595 - val_recall: 0.7266\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 69%|██████▉   | 11/16 [2:04:13<57:27, 689.48s/it]  \u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'num_projection_layers': 0, 'projection_dims': 224, 'dropout_rate': 0.1, 'vision_trainable': False, 'text_trainable': False, 'attention': True, 'lr': 0.0005, 'epochs': 10, 'batch_size': 64}\n",
            "Epoch 1/10\n",
            "446/446 [==============================] - 107s 203ms/step - loss: 0.5437 - accuracy: 0.7570 - precision: 0.7331 - recall: 0.5609 - val_loss: 0.5419 - val_accuracy: 0.8164 - val_precision: 0.9495 - val_recall: 0.7473\n",
            "Epoch 2/10\n",
            "446/446 [==============================] - 63s 140ms/step - loss: 0.3994 - accuracy: 0.8296 - precision: 0.7751 - recall: 0.7109 - val_loss: 0.4854 - val_accuracy: 0.8658 - val_precision: 0.9414 - val_recall: 0.8384\n",
            "Epoch 3/10\n",
            "446/446 [==============================] - 63s 141ms/step - loss: 0.3592 - accuracy: 0.8517 - precision: 0.8056 - recall: 0.7501 - val_loss: 0.4141 - val_accuracy: 0.8497 - val_precision: 0.8620 - val_recall: 0.9056\n",
            "Epoch 4/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.3336 - accuracy: 0.8627 - precision: 0.8190 - recall: 0.7715 - val_loss: 0.4105 - val_accuracy: 0.8331 - val_precision: 0.8267 - val_recall: 0.9287\n",
            "Epoch 5/10\n",
            "446/446 [==============================] - 63s 141ms/step - loss: 0.3060 - accuracy: 0.8754 - precision: 0.8345 - recall: 0.7955 - val_loss: 0.3871 - val_accuracy: 0.8757 - val_precision: 0.9116 - val_recall: 0.8882\n",
            "Epoch 6/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.3310 - accuracy: 0.8684 - precision: 0.8231 - recall: 0.7865 - val_loss: 0.4177 - val_accuracy: 0.8752 - val_precision: 0.9252 - val_recall: 0.8716\n",
            "Epoch 7/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.2923 - accuracy: 0.8832 - precision: 0.8463 - recall: 0.8069 - val_loss: 0.3811 - val_accuracy: 0.8794 - val_precision: 0.9380 - val_recall: 0.8650\n",
            "Epoch 8/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.3080 - accuracy: 0.8769 - precision: 0.8351 - recall: 0.8002 - val_loss: 0.4022 - val_accuracy: 0.8736 - val_precision: 0.9288 - val_recall: 0.8650\n",
            "Epoch 9/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.2713 - accuracy: 0.8897 - precision: 0.8539 - recall: 0.8196 - val_loss: 0.4909 - val_accuracy: 0.8596 - val_precision: 0.9553 - val_recall: 0.8144\n",
            "Epoch 10/10\n",
            "446/446 [==============================] - 67s 150ms/step - loss: 0.2611 - accuracy: 0.8939 - precision: 0.8630 - recall: 0.8220 - val_loss: 0.3988 - val_accuracy: 0.8783 - val_precision: 0.9411 - val_recall: 0.8600\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 75%|███████▌  | 12/16 [2:15:42<45:57, 689.44s/it]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'num_projection_layers': 0, 'projection_dims': 224, 'dropout_rate': 0.2, 'vision_trainable': False, 'text_trainable': False, 'attention': True, 'lr': 0.001, 'epochs': 10, 'batch_size': 32}\n",
            "Epoch 1/10\n",
            "446/446 [==============================] - 105s 201ms/step - loss: 0.5798 - accuracy: 0.7696 - precision: 0.7228 - recall: 0.6327 - val_loss: 0.4182 - val_accuracy: 0.8476 - val_precision: 0.8559 - val_recall: 0.9105\n",
            "Epoch 2/10\n",
            "446/446 [==============================] - 63s 140ms/step - loss: 0.3732 - accuracy: 0.8420 - precision: 0.7940 - recall: 0.7301 - val_loss: 0.3859 - val_accuracy: 0.8830 - val_precision: 0.9240 - val_recall: 0.8865\n",
            "Epoch 3/10\n",
            "446/446 [==============================] - 63s 141ms/step - loss: 0.3202 - accuracy: 0.8641 - precision: 0.8252 - recall: 0.7678 - val_loss: 0.4352 - val_accuracy: 0.8757 - val_precision: 0.9337 - val_recall: 0.8633\n",
            "Epoch 4/10\n",
            "446/446 [==============================] - 63s 141ms/step - loss: 0.2973 - accuracy: 0.8791 - precision: 0.8426 - recall: 0.7976 - val_loss: 0.3707 - val_accuracy: 0.8809 - val_precision: 0.9123 - val_recall: 0.8964\n",
            "Epoch 5/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.2886 - accuracy: 0.8815 - precision: 0.8464 - recall: 0.8010 - val_loss: 0.5681 - val_accuracy: 0.7852 - val_precision: 0.9563 - val_recall: 0.6893\n",
            "Epoch 6/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.2566 - accuracy: 0.8982 - precision: 0.8698 - recall: 0.8279 - val_loss: 0.5847 - val_accuracy: 0.7816 - val_precision: 0.9549 - val_recall: 0.6843\n",
            "Epoch 7/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.2593 - accuracy: 0.8941 - precision: 0.8651 - recall: 0.8200 - val_loss: 0.5186 - val_accuracy: 0.8242 - val_precision: 0.9579 - val_recall: 0.7531\n",
            "Epoch 8/10\n",
            "446/446 [==============================] - 64s 143ms/step - loss: 0.2493 - accuracy: 0.9010 - precision: 0.8742 - recall: 0.8318 - val_loss: 0.5971 - val_accuracy: 0.8008 - val_precision: 0.9671 - val_recall: 0.7067\n",
            "Epoch 9/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.2468 - accuracy: 0.9008 - precision: 0.8746 - recall: 0.8306 - val_loss: 0.5011 - val_accuracy: 0.8180 - val_precision: 0.9563 - val_recall: 0.7440\n",
            "Epoch 10/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.2393 - accuracy: 0.9036 - precision: 0.8792 - recall: 0.8343 - val_loss: 0.4473 - val_accuracy: 0.8466 - val_precision: 0.9569 - val_recall: 0.7912\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 81%|████████▏ | 13/16 [2:27:07<34:24, 688.09s/it]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'num_projection_layers': 0, 'projection_dims': 224, 'dropout_rate': 0.2, 'vision_trainable': False, 'text_trainable': False, 'attention': True, 'lr': 0.001, 'epochs': 10, 'batch_size': 64}\n",
            "Epoch 1/10\n",
            "446/446 [==============================] - 107s 204ms/step - loss: 0.6402 - accuracy: 0.7575 - precision: 0.7040 - recall: 0.6176 - val_loss: 0.4270 - val_accuracy: 0.7993 - val_precision: 0.7829 - val_recall: 0.9412\n",
            "Epoch 2/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.3868 - accuracy: 0.8345 - precision: 0.7792 - recall: 0.7244 - val_loss: 0.4477 - val_accuracy: 0.8726 - val_precision: 0.9104 - val_recall: 0.8840\n",
            "Epoch 3/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.3324 - accuracy: 0.8614 - precision: 0.8187 - recall: 0.7670 - val_loss: 0.5277 - val_accuracy: 0.7904 - val_precision: 0.9447 - val_recall: 0.7075\n",
            "Epoch 4/10\n",
            "446/446 [==============================] - 64s 143ms/step - loss: 0.2921 - accuracy: 0.8793 - precision: 0.8462 - recall: 0.7933 - val_loss: 0.4492 - val_accuracy: 0.8638 - val_precision: 0.9479 - val_recall: 0.8285\n",
            "Epoch 5/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.2856 - accuracy: 0.8853 - precision: 0.8507 - recall: 0.8084 - val_loss: 0.4142 - val_accuracy: 0.8747 - val_precision: 0.9506 - val_recall: 0.8442\n",
            "Epoch 6/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.2780 - accuracy: 0.8900 - precision: 0.8614 - recall: 0.8108 - val_loss: 0.4396 - val_accuracy: 0.8773 - val_precision: 0.9491 - val_recall: 0.8500\n",
            "Epoch 7/10\n",
            "446/446 [==============================] - 64s 143ms/step - loss: 0.2578 - accuracy: 0.8968 - precision: 0.8694 - recall: 0.8239 - val_loss: 0.4114 - val_accuracy: 0.8820 - val_precision: 0.9479 - val_recall: 0.8592\n",
            "Epoch 8/10\n",
            "446/446 [==============================] - 63s 141ms/step - loss: 0.2451 - accuracy: 0.9019 - precision: 0.8775 - recall: 0.8310 - val_loss: 0.3676 - val_accuracy: 0.8840 - val_precision: 0.9369 - val_recall: 0.8741\n",
            "Epoch 9/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.2381 - accuracy: 0.9029 - precision: 0.8756 - recall: 0.8365 - val_loss: 0.3897 - val_accuracy: 0.8736 - val_precision: 0.9250 - val_recall: 0.8691\n",
            "Epoch 10/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.2407 - accuracy: 0.9047 - precision: 0.8798 - recall: 0.8373 - val_loss: 0.3763 - val_accuracy: 0.8778 - val_precision: 0.9241 - val_recall: 0.8774\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 88%|████████▊ | 14/16 [2:38:35<22:56, 688.10s/it]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'num_projection_layers': 0, 'projection_dims': 224, 'dropout_rate': 0.2, 'vision_trainable': False, 'text_trainable': False, 'attention': True, 'lr': 0.0005, 'epochs': 10, 'batch_size': 32}\n",
            "Epoch 1/10\n",
            "446/446 [==============================] - 108s 206ms/step - loss: 0.5356 - accuracy: 0.7586 - precision: 0.7211 - recall: 0.5885 - val_loss: 0.4686 - val_accuracy: 0.8305 - val_precision: 0.9445 - val_recall: 0.7755\n",
            "Epoch 2/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.3910 - accuracy: 0.8355 - precision: 0.7893 - recall: 0.7119 - val_loss: 0.6264 - val_accuracy: 0.6786 - val_precision: 0.9376 - val_recall: 0.5228\n",
            "Epoch 3/10\n",
            "446/446 [==============================] - 63s 141ms/step - loss: 0.3600 - accuracy: 0.8439 - precision: 0.7911 - recall: 0.7421 - val_loss: 0.4784 - val_accuracy: 0.8586 - val_precision: 0.9357 - val_recall: 0.8318\n",
            "Epoch 4/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.3310 - accuracy: 0.8627 - precision: 0.8191 - recall: 0.7710 - val_loss: 0.3839 - val_accuracy: 0.8820 - val_precision: 0.9217 - val_recall: 0.8873\n",
            "Epoch 5/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.3480 - accuracy: 0.8551 - precision: 0.8040 - recall: 0.7653 - val_loss: 0.4587 - val_accuracy: 0.8580 - val_precision: 0.9456 - val_recall: 0.8210\n",
            "Epoch 6/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.3005 - accuracy: 0.8779 - precision: 0.8398 - recall: 0.7971 - val_loss: 0.5270 - val_accuracy: 0.8300 - val_precision: 0.9555 - val_recall: 0.7647\n",
            "Epoch 7/10\n",
            "446/446 [==============================] - 64s 143ms/step - loss: 0.2987 - accuracy: 0.8775 - precision: 0.8407 - recall: 0.7943 - val_loss: 0.3887 - val_accuracy: 0.8440 - val_precision: 0.8513 - val_recall: 0.9105\n",
            "Epoch 8/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.2738 - accuracy: 0.8891 - precision: 0.8539 - recall: 0.8175 - val_loss: 0.4976 - val_accuracy: 0.8528 - val_precision: 0.9592 - val_recall: 0.7995\n",
            "Epoch 9/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.2740 - accuracy: 0.8890 - precision: 0.8524 - recall: 0.8194 - val_loss: 0.4938 - val_accuracy: 0.8346 - val_precision: 0.9578 - val_recall: 0.7705\n",
            "Epoch 10/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.2620 - accuracy: 0.8965 - precision: 0.8660 - recall: 0.8271 - val_loss: 0.4922 - val_accuracy: 0.8372 - val_precision: 0.9580 - val_recall: 0.7746\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " 94%|█████████▍| 15/16 [2:50:05<11:28, 688.56s/it]\u001b[A"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'num_projection_layers': 0, 'projection_dims': 224, 'dropout_rate': 0.2, 'vision_trainable': False, 'text_trainable': False, 'attention': True, 'lr': 0.0005, 'epochs': 10, 'batch_size': 64}\n",
            "Epoch 1/10\n",
            "446/446 [==============================] - 109s 209ms/step - loss: 0.5480 - accuracy: 0.7493 - precision: 0.7091 - recall: 0.5702 - val_loss: 0.6177 - val_accuracy: 0.7847 - val_precision: 0.9552 - val_recall: 0.6893\n",
            "Epoch 2/10\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 0.4026 - accuracy: 0.8256 - precision: 0.7740 - recall: 0.6966 - val_loss: 0.5555 - val_accuracy: 0.7821 - val_precision: 0.9378 - val_recall: 0.6993\n",
            "Epoch 3/10\n",
            "446/446 [==============================] - 62s 140ms/step - loss: 0.3682 - accuracy: 0.8455 - precision: 0.7940 - recall: 0.7439 - val_loss: 1.1996 - val_accuracy: 0.3874 - val_precision: 0.6986 - val_recall: 0.0423\n",
            "Epoch 4/10\n",
            "446/446 [==============================] - 63s 141ms/step - loss: 0.3833 - accuracy: 0.8455 - precision: 0.7902 - recall: 0.7501 - val_loss: 0.4259 - val_accuracy: 0.8794 - val_precision: 0.9177 - val_recall: 0.8873\n",
            "Epoch 5/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.3225 - accuracy: 0.8655 - precision: 0.8202 - recall: 0.7800 - val_loss: 0.3978 - val_accuracy: 0.8326 - val_precision: 0.8335 - val_recall: 0.9163\n",
            "Epoch 6/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.3336 - accuracy: 0.8665 - precision: 0.8195 - recall: 0.7849 - val_loss: 0.7853 - val_accuracy: 0.5975 - val_precision: 0.9356 - val_recall: 0.3853\n",
            "Epoch 7/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.3067 - accuracy: 0.8767 - precision: 0.8369 - recall: 0.7969 - val_loss: 0.9170 - val_accuracy: 0.5408 - val_precision: 0.9263 - val_recall: 0.2916\n",
            "Epoch 8/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.3035 - accuracy: 0.8787 - precision: 0.8367 - recall: 0.8043 - val_loss: 0.4223 - val_accuracy: 0.8206 - val_precision: 0.8141 - val_recall: 0.9254\n",
            "Epoch 9/10\n",
            "446/446 [==============================] - 63s 142ms/step - loss: 0.2924 - accuracy: 0.8808 - precision: 0.8386 - recall: 0.8094 - val_loss: 0.4131 - val_accuracy: 0.8320 - val_precision: 0.8299 - val_recall: 0.9213\n",
            "Epoch 10/10\n",
            "446/446 [==============================] - 63s 141ms/step - loss: 0.2864 - accuracy: 0.8868 - precision: 0.8474 - recall: 0.8183 - val_loss: 0.4024 - val_accuracy: 0.8742 - val_precision: 0.9185 - val_recall: 0.8774\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 16/16 [3:02:19<00:00, 683.75s/it]\n"
          ]
        }
      ],
      "source": [
        "h = ta.Scan(x = X_train, y= y_train, params = params, model = multimodal_model, x_val = X_test, y_val = y_test, experiment_name = 'multi1', save_weights=False, print_params=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'num_projection_layers' : [1],\n",
        "    'projection_dims' : [128, 224],\n",
        "    'dropout_rate' : [0.1, 0.2],\n",
        "    'vision_trainable' : [False],\n",
        "    'text_trainable' : [False],\n",
        "    'attention' : [True],\n",
        "    'lr' : [0.001, 0.0005],\n",
        "    'epochs' : [10],\n",
        "    'batch_size' : [32]\n",
        "}"
      ],
      "metadata": {
        "id": "wC_IOmzcm2BE"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = ta.Scan(x = X_train, y= y_train, params = params, model = multimodal_model, x_val = X_test, y_val = y_test, experiment_name = 'multi1', save_weights=False, print_params=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNyODIYMm-mo",
        "outputId": "495afa3f-c151-4574-b752-01a4e2e04726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/8 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'num_projection_layers': 1, 'projection_dims': 128, 'dropout_rate': 0.1, 'vision_trainable': False, 'text_trainable': False, 'attention': True, 'lr': 0.001, 'epochs': 10, 'batch_size': 32}\n",
            "Epoch 1/10\n",
            "446/446 [==============================] - 120s 208ms/step - loss: 0.4790 - accuracy: 0.7883 - precision: 0.7164 - recall: 0.6365 - val_loss: 0.4602 - val_accuracy: 0.8346 - val_precision: 0.9397 - val_recall: 0.7871\n",
            "Epoch 2/10\n",
            "446/446 [==============================] - 57s 127ms/step - loss: 0.3078 - accuracy: 0.8746 - precision: 0.8324 - recall: 0.7957 - val_loss: 0.5246 - val_accuracy: 0.7400 - val_precision: 0.9164 - val_recall: 0.6446\n",
            "Epoch 3/10\n",
            "446/446 [==============================] - 57s 129ms/step - loss: 0.2658 - accuracy: 0.8926 - precision: 0.8580 - recall: 0.8241 - val_loss: 0.4445 - val_accuracy: 0.8383 - val_precision: 0.8972 - val_recall: 0.8384\n",
            "Epoch 4/10\n",
            "446/446 [==============================] - ETA: 0s - loss: 0.2417 - accuracy: 0.9045 - precision: 0.8772 - recall: 0.8400"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}